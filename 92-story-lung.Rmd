# Story lungs: eXplainable predictions for post operational risks {#story-lungs}

*Authors: Maciej Bartczak (UW), Marika Partyka (PW)*

*Mentors: Aleksandra Radziwiłł (McKinsey & Company), Maciej Krasowski (McKinsey & Company)*




## Introduction 
 Science allows us to understand the world better. New technologies, data collection solves the problems not only of large companies but also of ordinary people. Especially if human life is at stake.
 They say that cancer is the killer of the 21st century. That's why even small attempts to subdue this problem are important. 
 In our work, we deal with lung cancer. We try to predict the chances of survival of a patient who has had a tumor removal surgery. We try different approaches.

## Model 

Place a description of the model(s) here. Focus on key information on the design and quality of the model(s) developed.

## Explanations

We are based on 3 methods of explaining models, mainly Ceteris Paribus as well as Shap and Variable Importance.
Of course, it is our goal to understand on what basis our model has found a chance of survival of a given patient. For example, let's take a patient with the following variable values: 
- `date_start_treatment` 2007-03-01
- `sex` M
- `histopatological_diagnosis` rak niedrobnokomórkowy
- `years_smoking` 35
- `lung_cancer_in_family` No
- `symptoms` No
- `stadium_uicc` IIIA
- `age` 54
- `time_to_surgery` 0
- `volume` 125
Our most recent model indicated that the chances of survival after surgery for such a patient are $24\%.$
Here we have an explanation of this result by SHAP.
```{r, cache=FALSE, out.width="600", fig.align="center", echo=FALSE}
knitr::include_graphics('images/92_shap_1.png')
```

According to our intuition, the lack of symptoms increases the chance of survival, quite advanced stage of UICC equal to IIIA reduces these chances. We may also notice that the prognosis is worse because our patient is a man. However, it will be best if we refer to the results of another method - Ceteris Paribus.
```{r, cache=FALSE, out.width="600", fig.align="center", echo=FALSE}
knitr::include_graphics('images/92_cp_1.png')
```
Here we see 3 variables that show well how a parameter change works for or against the patient. This confirms that women have a better prognosis of survival after surgery, the symptoms of the disease do not herald the best, and also the younger we are, the better we are able to cope with convalescence. 
```{r, cache=FALSE, out.width="600", fig.align="center", echo=FALSE}
knitr::include_graphics('images/92_cp_2.png')
```

Here too, the model shows that if our patient's cancer was classified as much lighter, his chances would increase.

Let's take a look at another method for the whole data set - Variable Importance.
```{r, cache=FALSE, out.width="600", fig.align="center", echo=FALSE}
knitr::include_graphics('images/92_vi_1.png')
```
 The most important one seems to be the variable that says when the patient started treatment. The second most important is the UICC stage. Interestingly, the period of time the patient smoked cigarettes does not affect the outcome too much.

 But using model explanations not only helps to explain the result of the prediction, it can also give a hint how to improve our model.
 
 When we built the model on all variables, the explanations allowed us to find correlations. Let's compare the CeterisParibus results for the full model and the deleted dependent variables.
 
```{r, cache=FALSE, out.width="600", fig.align="center", echo=FALSE}
knitr::include_graphics('images/92_cp_3.png')
```
 In the picture above you can see that the influence of two correlated variables was distributed between them, but after leaving only one of these variables, the influence accumulated on it (picture below).
 
```{r, cache=FALSE, out.width="600", fig.align="center", echo=FALSE}
knitr::include_graphics('images/92_cp_4.png')
```

At this stage we can already conclude that the techniques of model explanations are not only useful at the end of our journey. They can give us tips on how to transform data or which variables should be deleted.
 



## Summary and conclusions 

Here add the most important conclusions related to the XAI analysis.
What did you learn? 
Where were the biggest difficulties?
What else did you recommend?

